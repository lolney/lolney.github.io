<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0"> <meta name="generator" content="Hugo 0.37" /> 
<title>Readings - Luke Olney</title>
<meta property="og:title" content="Readings - Luke Olney">       

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>



<script type="text/javascript" src="https://lukeolney.me/js/readmore.js"></script> 


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116576963-1"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag() { dataLayer.push(arguments); }
	gtag('js', new Date());

	gtag('config', 'UA-116576963-1');
</script>


<link rel="stylesheet" href="https://lukeolney.me/css/main.css" media="all">
<link rel="stylesheet" href="https://lukeolney.me/css/fonts.css">
  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="https://lukeolney.me/" class="nav-logo">
    <img src="https://lukeolney.me/images/logo.png" 
         width="50" 
         height="50" 
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/projects/">Projects</a></li>
    
    <li><a href="/readings/">Readings</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
  </ul>
</nav>

      </header>


<main class="content">

    <article>
        <header>
            <h1 class="article-title">Readings</h1>
        </header>
        
        <p>Short commentaries on technical blogs or papers that I&rsquo;ve read:</p>

    </article>
    <ul>

        <div class="list">
            
            <h2 class="list-title">2018</h2>
             <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://krebsonsecurity.com/2017/01/who-is-anna-senpai-the-mirai-worm-author/">Who is Anna-Senpai, the Mirai Worm Author</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 18 October 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/mirai/">18 October 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/security">Security</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>This is Brian Krebs&rsquo; fascinating investigative report into the Mirai botnet, the network used to launch some of the largest DDoS attacks on the Internet to date. Krebs&rsquo; account include testimony and private conversations with the hackers themselves, who were later charged by the FBI for their activities. It reveals how much the Internet remains a free-for-all, kill-or-be-killed world, where rogue security companies can surreptitiously hijack competitors&rsquo; IP addresses<a href="https://en.wikipedia.org/wiki/BGP_hijacking">1</a> or take down their services with DDoS hits.</p>

<p>Mirai was the covert arm of a legitimate business, ProTraf Solutions, which offered DDoS protection services in the competitive Minecraft server cottage industry. In early attacks, it sought competitive advantage by DDoSing a competing service, ProxyPipe, which forced many of ProxyPipe&rsquo;s customers to switch to ProTraf.</p>

<p>Krebs is able to connect ProTraf CEO&rsquo;s description of his programming language skills to that of his blackhat persona &ndash; and professed Mirai author &ndash; Anna-Senpai. He also mentions a Github username, shared among a number of online accounts that includes a number of Minecraft forums and a Reddit account. This has several interesting posts, including awfully suspicious speculation about the nature of a DDoS attack on the Rutgers campus.</p>

<p>After the ProxyPipe CEO, remarkably, managed through several layers of ISPs to get the Ukrainian-based control servers for the botnet disconnected, Anna-Senpai taunts him with the knowledge he is responsible. This is just one piece of evidence for his petty-vindictive persona &ndash; he is constantly taking down people he gets into disagreements with, like a hapless server operator and, on multiple occasions, Krebs himself.</p>

<p>The ProxyPipe CEO evenutally makes the connection that Krebs describes between Anna-Senpai and his real life persona. In fact, the two had previously been friends and collaborators on Minecraft projects, before, he says, Anna-Senpai fell to the bad influence of places like Hackforums.net.</p>

<p>His sloppiness with his online personas and his hubris eventually does the Mirai creator in, as the FBI track him down after a broad investigation. He is indicted, and now, as of the time of writing, serves the FBI as part of a plea agreement.<a href="http://www2.philly.com/philly/business/mirai-cyberattack-rutgers-student-paras-jha-fbi-20180919.html">2</a></p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://googleprojectzero.blogspot.com/2018/09/a-cache-invalidation-bug-in-linux.html">Linux Cache Invalidation Bug</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 02 October 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/linux-cache-invalidation-bug/">02 October 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/systems">Systems</a>
        <a href="/tags/security">Security</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>This is a detailed writeup from Project Zero about a bug in the Linux Kernel, introducing by an optimization with an unconsidered edge case.</p>

<p>A quick summary of the relevant OS concepts: Virtual Memory Areas (VMAs), which include the code segment, data segment, and heap, have special rules[1] that must be applied when a page fault occurs. The mappings of addresses to VMAs are stored in <code>vm_area_struct</code>s, which are stored in a red-black tree or possibly cached in a per-thread 4-member array. Whenever a VMA is freed in any thread for the process, all of these per-thread caches must be invalidated.</p>

<p>To avoid having to do this expensive operation, each cache is tagged with a <code>seqnum</code> equal to the <code>seqnum</code> of the per-process <code>mm_struct</code>; when the <code>seqnum</code>s are out of sync, we know to invalidate the cache. Because the <code>seqnum</code> can overflow, though, we still need to flush all the caches every time that happens.</p>

<p>In the patch in question, someone added the further optimization of simply avoiding the flush if the process is single-threaded. They reasoned that VMA lookups would always trigger the update of the cache <code>seqnum</code> and <code>mm_struct</code> <code>seqnum</code> simultaneously, avoiding the need for the flush.</p>

<p>However, this added a (normally) rather unlikely bug in the case that, immediately after incrementing the <code>mm_struct</code> <code>seqnum</code> to wrap to zero, a second thread is created, pushing the <code>seqnum</code> back up to <code>0xffffffff</code> and making the cache in the first thread appear valid again.</p>

<p>The authors manage to exploit the bug first by doing a large number of VMA remappings to trigger the overflow, then creating a fake VMA using the pointers from the deallocated one &ndash; leaked to logs by a warning message &ndash; to bypass Kernel controls. The VMA contains a fault handler that is used on page faults, which can be used, for instance, to run a binary with root privileges.</p>

<p>[1] <a href="http://students.mimuw.edu.pl/SO/Linux/Kod/include/linux/mm.h.html">http://students.mimuw.edu.pl/SO/Linux/Kod/include/linux/mm.h.html</a></p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://pdfs.semanticscholar.org/6a39/082e14e08fcc4f853b07e4d797163afadde1.pdf">Log Structured Merge Trees</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 19 May 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/log-structured-merge-trees/">19 May 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/databases">Databases</a>
        <a href="/tags/data-structures">Data Structures</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>The log-structured merge tree is used in the storage engine of many databases, including Cassandra<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>. It describes a data structure, often contrasted with B-trees, that&rsquo;s mainly designed as a strategy for managing writes to disk.</p>

<p>The basic approach is this: Maintain a collection of stores, increasing geometrically in size from the top down. Store records in the top level first. When level L_i fills up, merge it into L_i+1, emptying L_i.</p>

<p>Each level is itself a key-value store. Lower levels are implemented as B+ trees, filled in breadth-first order to avoid wasting space and allow for more sequential reads. Lookups proceed by checking for the key in L_0, then proceeding to the next level if the key isn&rsquo;t found.</p>

<pre><code>        [][][]               &lt;--- L_0: memory (updated in place)
      [][][][][][]           &lt;--- L_1: disk (updated with a merge)
[][][][][][][][][][][][]     &lt;--- L_2: disk (updated with a merge)
</code></pre>

<p>The log-structured approach contrasts with the update-in-place approach: while the former does sequential writes, relying on additional sequential IO to manage the structure asynchronously, the latter does random reads &ndash; relying on a single seek for each read.</p>

<p>The bLSM<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup> authors note the choice that web services face when storing small objects: optimize for low-latency reads, or for high-throughput writes. B-trees meet the former requirement, and LSMTs meet the latter by making sure that all writes to disk are batched.</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_manage_ondisk_c.html">https://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_manage_ondisk_c.html</a>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2"><a href="http://www.eecs.harvard.edu/~margo/cs165/papers/gp-lsm.pdf">http://www.eecs.harvard.edu/~margo/cs165/papers/gp-lsm.pdf</a>
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
</ol>
</div>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://blog.twitter.com/engineering/en_us/a/2010/introducing-flockdb.html">Graph Databases at Twitter</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 10 May 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/graph-dbs-at-twitter/">10 May 2018</a>
            </time>
            <ul class="article-taxonomy">
     
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>&ldquo;Graph databases&rdquo; seem to be mostly wrappers over relational databases that are optimized for certain graph operations. One example is Twitter&rsquo;s FlockDB &ndash; an apparently long-abandoned project that&rsquo;s nonetheless a solid demonstration of the principle. FlockDB uses MySQL as as storage engine, storing its edges as MySQL records.</p>

<p>Flock is optimized for queries that involve a user&rsquo;s followers and people who follow that user. Like, which of my followers is following President Obama? These are the people A who satisfy the relations follows(Me, A) and follows(A, Obama). Flock contains a single table for for all A s.t. follows(Me, A). And the reverse is also stored, so follows(A, Obama) is just as efficient. So that query ends up being a single query on the <code>me</code> partition combined with a query on the <code>Obama</code> partition.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://github.com/bodil/im-rs/blob/master/src/hashmap.rs">An Immutable Hashmap in Rust</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 09 May 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/rust-immutable-hashmap/">09 May 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/data-structures">Data Structures</a>
        <a href="/tags/rust">Rust</a>
        <a href="/tags/code-reading">Code Reading</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>This is an implementation of the &ldquo;hash array mapped trie,&rdquo; a purely functional hashmap. In an ordinary trie hashmap, the keys are stored as bitstrings in a trie, as follows:</p>

<pre><code>   0
  / \
  1 0
/ \ / \
1 0 1 0 
| | | |
X F D E
</code></pre>

<p>This saves space compared to a traditional Hashmap, and it means resizings are never necessary.</p>

<p>The HAMT improves on this by instead storing in each node a table with N (32 with 32-bit words) entries, with each entry containing a pointer to another node. When traversing or inserting a key, you consider the most significant T=log_2(N)=5 bits of the hash; this indexes to either a submap, a value, or nil. It starts out as a value, then a submap is added when a new hash collides with an existing one. This submap then behaves like the root map, but with the next 5 bits of the hash as a key. With T=2:</p>

<pre><code>00 01 10 11
|   |  |  |
|   G     O
|
00 01 10 11
|  |  |  |
E     D
</code></pre>

<p>This means that lookup time is reduced to log_N(n) from log_2(n), without taking up much additional space.</p>

<p>Another note: to save space in the tables, only the keys that point to actual values or nodes are represented. This is done by adding an N-bit bitmap to each node, with the ith bit representing whether that pointer is nil. Then, the index into the table is found by calculating the hamming weight (number of 1s) in the first i bits of the bitmap, where i is also the T-bit key into the subtable.</p>

<pre><code>// Modified above example
bitmap: 1101
0 1 2
| | |
| G O
|
...
</code></pre>

<p>This means that the table must be resized every time a new key is inserted. Still, the immutable version is significantly slower than the equivalent mutable version, by a factor of about 10 with 1000 inserts.</p>

<pre><code>test hashmap_insert_10         ... bench:       5,991 ns/iter (+/- 185)
test hashmap_insert_100        ... bench:     197,136 ns/iter (+/- 9,000)
test hashmap_insert_1000       ... bench:   2,990,670 ns/iter (+/- 133,638)
test hashmap_insert_mut_10     ... bench:       1,961 ns/iter (+/- 191)
test hashmap_insert_mut_100    ... bench:      29,460 ns/iter (+/- 2,971)
test hashmap_insert_mut_1000   ... bench:     305,106 ns/iter (+/- 17,927)
</code></pre>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://en.wikipedia.org/wiki/100_prisoners_problem">100 Prisoners</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 03 May 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/100-prisoners/">03 May 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/probability">Probability</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>The 100 prisoners problem is a probability thought exercise with an unintuitive solution, kind of like the Monty-Hall problem. The setup is this: there are 100 numbers in drawers, each corresponding to one of 100 prisoners. Each prisoner is allowed to pick 50 drawers, but the drawers are reset after each prisoner makes their choice (and there&rsquo;s no communication between prisoners). The goal is for each prisoner to find their number &ndash; if that happens, they escape their sentence.</p>

<p>The naive solution is to pick the 50 drawers at random, giving each prisoner a 50% chance of success (and a vanishingly small chance &ndash; .50^100 &ndash; for all 100 prisoners to pick the correct number). But there&rsquo;s a strategy that drastically improves the odds of success, bringing it to ~30%.</p>

<p>This strategy does not appear much different from the naive one, but it relies on the hidden correlation between success and failure in the permutation cycles to shape the search space. Namely, the prisoners want to search a set that&rsquo;s as different as possible from everyone else&rsquo;s &ndash; since they know the world where they succeed is one in which they all pick different boxes.</p>

<p>The the <a href="https://en.wikipedia.org/wiki/100_prisoners_problem#Monty_Hall_problem">Monty Hall-inspired analogy on the Wikipedia page</a> gives a good explanation of this. Essentially, the contestants choose doors (over two rounds) in a way that they&rsquo;re never picking the same door in the same round.</p>

<p>Consider how the prisoners could design their choices similarly. If, in the case where each prisoner is only allowed to search a single box, all prisoners just choose box 1, there is no possibility of success: Only one prisoner will find the correct number. Choosing a box at random has some probability of success, if extremely low: 100^-100. If instead each prisoner i chooses the ith box, the chances are improved: it&rsquo;s now 1/(100!), since each correctly chosen box constrains the options for future boxes. If just you expand that search to the next 50 boxes, you still don&rsquo;t get the optimal solution - starting with a <sup>1</sup>&frasl;<sub>2</sub> chance of success for the first prisoner, the next 50 prisoners slowly widdle that down to 1 (the resulting probability is 50^50/(100!/50!)).</p>

<p>It follows along these lines that permutation cycles, being disjoint, are better for structuring the search. But I&rsquo;m not sure how to make this intuition concrete, if that&rsquo;s even possible.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://github.com/urbit/urbit">Urbit</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 02 May 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/urbit/">02 May 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/distributed-systems">Distributed Systems</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>I found Urbit when somebody compared it to the &ldquo;decentralized Internet&rdquo; that <em>Silicon Valley</em>&rsquo;s Pied Piper is building. It turns out that it&rsquo;s even more ambitious than that &ndash; an attempt to rebuild the whole software stack from the Kernel up &ndash; but this summary will focus on the network part.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="http://sigops.org/sosp/sosp13/papers/p33-david.pdf">Everything You Always Wanted to Know About Synchronization but Were Afraid to Ask</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 19 April 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/synchronization/">19 April 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/programming">Programming</a>
        <a href="/tags/synchronization">Synchronization</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>This paper is an overview of synchronization methods across the hardware stack, with an analysis that attributes high-level performance differences to low-level hardware constraints.</p>

<p>Among the key takeaways:</p>

<p>Latency of atomic operations: There is a heavy penalty for cross-socket sharing - ie, passing data between cores (or hyperthreads). This outweighs other sources of latency by far.</p>

<p>Locking vs message passing: Message passing is better when data has high contention, locking with low contention.</p>

<p>Performance of different types of locks: Each of the nine locks considered is the best performer in certain situations. The ticket lock is the best performer in most low-contention cases, though&ndash;the &ldquo;ticket lock&rdquo; being a spinlock that uses a FIFO queue to determine which thread is allowed to proceed.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://news.ycombinator.com/item?id=11939851">Alan Kay&#39;s Hacker News AMA</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 14 April 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/alan-kay/">14 April 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/software-engineering">Software Engineering</a>
        <a href="/tags/computing-history">Computing History</a>
        <a href="/tags/programming-languages">Programming Languages</a>
        <a href="/tags/hci">HCI</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>Here are some highlights for the Hacker News AMA of Alan Kay, pioneering researcher in graphical user interfaces and object-oriented programming.</p>

<blockquote>
<p><a href="https://news.ycombinator.com/item?id=11940433">Part of this was that the rather good idea of parsing non-command messages in each process &ndash; we used this in the first Smalltalk at Parc &ndash; became much too ad hoc because there was not a strong attempt to intertwine a real language around the message structures (this very same thing happened with http &ndash; just think of what this could have been if anyone had been noticing</a></p>
</blockquote>

<p>Mr. Kay thinks that current message-passing protocols (like HTTP or Unix process communication) don&rsquo;t stand up well to the formal treatment of message-passing in Smalltalk. As background, Smalltalk&rsquo;s message handling was done by dynamic dispatch on objects. This would allow inheritance of message handling, so that, eg, the default implementation was to return <code>messageNotUnderstood</code>.<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup> There is perhaps also the advantage that message fields are parsed by the language parser, making it an actual component of the language that might allow, eg, for easier static analysis. I&rsquo;m only speculating on the specifics, though, since Mr. Kay doesn&rsquo;t make this part clear.</p>

<blockquote>
<p><a href="https://news.ycombinator.com/user?id=alankay1">&ndash; I was surprised that the HN list page didn&rsquo;t automatically refresh in my browser (seems as though it should be live and not have to be prompted &hellip;)
</a></p>
</blockquote>

<p>Mr. Kay comments earlier on the <a href="https://news.ycombinator.com/item?id=11940276">&ldquo;worse is better&rdquo; vs &ldquo;better is better&rdquo;</a> approaches to user interface design, but this, I think, is a better, more concrete way of answering the question. Hacker News is itself an embodiment of &ldquo;worse is better&rdquo;, avoiding new features and maintaining <a href="https://news.ycombinator.com/item?id=11940044">what one commenter points out</a> is an &ldquo;old school&rdquo; feel. Mr. Kay counters with an interesting critique, saying that if old school means how things were done, eg, at PARC, that&rsquo;s more than this website can do! That&rsquo;s to say that old school software was often more capable than we give it credit for, not static, as we often imagine it, but experimenting with new modes of interaction just like fast-moving software today. We shouldn&rsquo;t, therefore, fold up new features simply because they wouldn&rsquo;t be &ldquo;old school&rdquo; enough, as if the researchers at PARC and Bell Labs achieved the perfect form of computing.</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><a href="https://courses.cs.washington.edu/courses/cse505/99au/oo/smalltalk-concepts.html">https://courses.cs.washington.edu/courses/cse505/99au/oo/smalltalk-concepts.html</a>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
</ol>
</div>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://pdos.csail.mit.edu/~rtm/roofnet-b.pdf">MIT Roofnet Mesh Network</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 11 April 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/roofnet/">11 April 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/networking">Networking</a>
        <a href="/tags/distributed-systems">Distributed Systems</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>Roofnet is a WiFi mesh network for increasing Internet access in urban areas. It&rsquo;s designed to be easy to set up: Users just need to place antennae on their roofs, and there&rsquo;s no need surveys to determine the optimum place to put them &ndash; since the network makes up the difference in performance. It does that, in part, though its routing protocol, which chooses routes that maximize bitrate and minimize loss-rate. It also introduces a new protocol that maximizes throughput no matter the loss rate &ndash; transmitting at a lower bitrate can improve performance by avoiding re-transmissions, and this protocol improves on the heuristics used by its predecessors (although not described in detail here).</p>

<p>In summary: Some number of nodes in the network have wired access to the Internet. The rest of the nodes need to route their packets to these gateway nodes, with some number of hops. Roofnet does that without much performance loss by choosing the highest-throughput routes, using multiple links if necessary.</p>

            </div>
        </div>
    </section>
</article>  
        </div>

        


<ul class="page-links">
  <li 
    class="page-links-disabled">
    <a href="" aria-label="Previous"><span aria-hidden="true">&lt;&#160;</span></a>
  </li>
  
  
  
  
  
   
    
    
  
  
    <li
      class="page-links-active"><a href="/readings/">1</a>
    </li>
    
  
  
  
  
   
    
    
  
  
    <li
      ><a href="/readings/page/2/">2</a>
    </li>
    
  
  
  
  
   
    
    
  
  
    <li
      ><a href="/readings/page/3/">3</a>
    </li>
    
  
  <li
    >
    <a href="/readings/page/2/" aria-label="Next"><span aria-hidden="true">&#160;&gt;</span></a>
  </li>
</ul>



</main>

<footer class="footer">
  <ul class="footer-links">
    <li>
      <a href="" type="application/rss+xml" target="_blank">
        <i class="fa fa-rss"></i> RSS feed</a>
    </li>
    <li>
      <a href="https://github.com/lolney">
        <i class="fa fa-github"></i> Github</a>
    </li>
  </ul>
</footer>

</div>

</body>

</html>