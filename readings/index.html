<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0"> <meta name="generator" content="Hugo 0.37" /> 
<title>Readings - Luke Olney</title>
<meta property="og:title" content="Readings - Luke Olney">       

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>



<script type="text/javascript" src="https://lukeolney.me/js/readmore.js"></script> 


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116576963-1"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag() { dataLayer.push(arguments); }
	gtag('js', new Date());

	gtag('config', 'UA-116576963-1');
</script>


<link rel="stylesheet" href="https://lukeolney.me/css/main.css" media="all">
<link rel="stylesheet" href="https://lukeolney.me/css/fonts.css">
  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="https://lukeolney.me/" class="nav-logo">
    <img src="https://lukeolney.me/images/logo.png" 
         width="50" 
         height="50" 
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/projects/">Projects</a></li>
    
    <li><a href="/readings/">Readings</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
  </ul>
</nav>

      </header>


<main class="content">

    <article>
        <header>
            <h1 class="article-title">Readings</h1>
        </header>
        
        <p>Short commentaries on technical blogs or papers that I&rsquo;ve read:</p>

    </article>
    <ul>

        <div class="list">
            
            <h2 class="list-title">2019</h2>
             <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://github.com/facebook/prepack">The Prepack Compiler</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 30 April 2019 ">
                <a title="Permalink" href="https://lukeolney.me/readings/prepack/">30 April 2019</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/web">Web</a>
        <a href="/tags/javascript">Javascript</a>
        <a href="/tags/compilers">Compilers</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                

<p>Prepack is an experimental optimizing Javascript compiler. The existing major Javascript compilers, like Babel or Closure, focus on other things: code size reduction for the former, backwards compatibility for the latter. Prepack is all about optimization: function inlining, loop unrolling, and other transformations that shift some of the work to compile time.</p>

<h2 id="how-it-works">How it works</h2>

<p>It runs your code, then generates an optimized version that returns the same results. This makes it very good at optimizing, for example, a call to fib(10), which returns the 10th Fibonacci number.</p>

<p>It’s limited, by default, to code along the global path — ie, what’s run in the initialization phase — but it can also run specific code that you direct it to do so, as long as any state it depends on are defined by the time the initialization phase in complete.</p>

<h3 id="symbolic-execution-engine">Symbolic Execution Engine</h3>

<p>Certain results will depend on state, e.g., Date.now(), that can’t be determined at compile time. These can be substituted with abstract values, allowing optimizations to still be made over code that depends on them.</p>

<p>Here are some examples that I tried with the <a href="https://prepack.io/repl.html">Prepack repl</a> that could in principle be optimized, but aren&rsquo;t:</p>

<p>Eg 1:</p>

<pre><code>let now = Date.now();
now += 1;
now -= 1;
</code></pre>

<p>In this case, the compiler can deduce that the value of <code>now</code> (which could be any integer) is the same whether or not lines 2 and 3 execute, so it should optimize them away.</p>

<p>Eg 2:</p>

<pre><code>function f() {
    let now = Date.now()
    if(now * 2 == 12) {
        return 0;
    } else {
        return 1;
    }
}
</code></pre>

<p>Here, the result only depends on whether now is equal to 6. The abstract interpreter can replace the result with an abstract data type equivalent to (Date.now == 6 ? 0 : 1).</p>

<p>(This shows the result of a control flow merge that results in a conditional abstract value.)</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://overreacted.io">Notes on Overreacted</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 20 March 2019 ">
                <a title="Permalink" href="https://lukeolney.me/readings/overreacted-notes/">20 March 2019</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/react">React</a>
        <a href="/tags/web">Web</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                

<p>Here are my notes on a few of my favorite posts on Overreacted, the blog of the React Core team&rsquo;s Dan Abramov.</p>

<h3 id="writing-resilient-components-https-overreacted-io-writing-resilient-components"><a href="https://overreacted.io/writing-resilient-components/">Writing Resilient Components</a></h3>

<ul>
<li>Things that don’t matter: too much deference on opinionated style guides/lint configs, cargo cult rules like “don’t call <code>setState</code> in <code>componentDidMount</code>. The former often puts too much emphasis on aesthetics and just creates conflict and stress without any improvement in maintainability.

<ul>
<li>It&rsquo;s really just important to have <em>some</em> set of rules, so that auto formatting is always consistent</li>
</ul></li>
</ul>

<h5 id="don-t-stop-the-data-flow">Don’t stop the data flow</h5>

<ul>
<li>For derived state, memoization is cleaner than <code>getDerivedStateFromProps</code>. <code>componentDidUpdate</code> is an option, but causes double renders.</li>
<li>Make sure that side effects are repeated on prop or state updates (eg, calls in <code>componentDidMount</code> may have to be repeated in <code>componentDidUpdate</code>)

<ul>
<li>Alternatively, the <code>useEffect</code> hook combines all lifecycle methods and makes prop, state dependencies explicit</li>
</ul></li>
<li>Be careful when comparing function props across updates: methods retain their identity across renders, but functions may not. The <code>useCallback</code> hook helps make this more explicit by memoizing closures so that their identity changes iff an element in the dependency array changes.</li>
</ul>

<h5 id="always-be-ready-to-render">Always be ready to render</h5>

<ul>
<li>Derived state can also have the &ldquo;blowing away&rdquo; problem: local state updates are overriden by props updates

<ul>
<li>Fix this by making components fully controlled, limiting state updates to a container component</li>
</ul></li>
</ul>

<h5 id="no-component-is-a-singleton">No component is a singleton</h5>

<ul>
<li>Any component, even something like a nav bar, might need to be rendered twice</li>
<li>Avoid global state for that reason</li>
</ul>

<h5 id="keep-the-local-state-isolated">Keep the Local State Isolated</h5>

<ul>
<li>What state should remain local vs. in a central (eg, Redux) store?</li>
<li>Try asking this question: if a component is rendered twice, what state should be updated in the other component when updated in one?</li>
<li>Local state should generally be limited to presentational state (eg, are these comments expanded?) or ephemeral state (eg, text in a comment field that hasn&rsquo;t been submitted)</li>
</ul>

<h3 id="why-do-we-write-super-props">Why do we write super(props)?</h3>

<ul>
<li>ES6 classes require super() to be called in the first line of the constructor (if at all), so that super class fields are initialized if you want to call super class methods</li>
<li>React requires super(props) mainly so that this.props is accessible in the constructor</li>
<li>But it’s not strictly necessary, since React initializes this.props after instantiating your opponent anyway</li>
</ul>

<h3 id="why-do-react-elements-have-typeof-property">Why do React elements have typeof property?</h3>

<ul>
<li>React escapes strings to prevent XSS attacks</li>
<li>Of course, it’s still vulnerable to attacks under certain conditions - eg, this renders arbitrary html:
<code>&lt;div dangerouslySetInnerHtml: {_html: “&lt;script&gt;stealPassword() &lt;/script&gt;”}&gt;</code></li>

<li><p>Could happen if you spread user input on a div</p></li>

<li><p>Could also happen if your server serves JSON where you expect text, and you get his:</p></li>
</ul>

<pre><code>let expectedTextButGotJSON = {
  type: 'div',
  props: {
    dangerouslySetInnerHTML: {
      __html: '/* put your exploit here */'
    },
  },
  // ...
};
let message = { text: expectedTextButGotJSON };

// Dangerous in React 0.13
&lt;p&gt;
  {message.text}
&lt;/p&gt;
See: http://danlec.com/blog/xss-via-a-spoofed-react-element
</code></pre>

<p>React protects against this by adding the typeof: symbol(‘react.elemt’) to React elements, which can’t be replicated in JSON. So, it’s a very specific fix - but it does enable the typeof function on React elements</p>

<h3 id="why-do-hooks-rely-on-call-order">Why do hooks rely on call order?</h3>

<p>useState can be used multiple times to create multiple state variables:</p>

<pre><code>const [a, setA] = useState(1);
const [b, setB] = useState(2);

const [b, setB] = useState(2);
useState(a) {
let current = a;

let setA = (a) =&gt; {
current = a;
};

return current;
}
</code></pre>

<p>This (supporting multiple useState calls) is mostly useful so that we can extract stateful logic into custom hooks that use useState:</p>

<p>This useWindowWidth hook outputs the window width as it changes with lifecycle updates (though apparently the same as just using window.innerWidth?):</p>

<pre><code>function useWindowWidth() {
// Declare some state and effects in a custom Hook
const [width, setWidth] = useState(window.innerWidth);
useEffect(() =&gt; {
// ...
});
return width;
}
</code></pre>

<p>Dan presents a number of solutions that involve passing an identifying key, and points out how each in turn fails to meet these requirements, or requires a lot of additional setup.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://hacks.mozilla.org/2019/03/fast-bump-allocated-virtual-doms-with-rust-and-wasm/">Dodrio: Virtual DOMs in Rust</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 14 March 2019 ">
                <a title="Permalink" href="https://lukeolney.me/readings/rust-virtual-doms/">14 March 2019</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/rust">Rust</a>
        <a href="/tags/browser-tech">Browser tech</a>
        <a href="/tags/javascript">Javascript</a>
        <a href="/tags/react">React</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                

<p>Javascript ecosystem tools like ESLint, Babel, NPM, or Webpack have traditionally been written in Javascript and run on the Node runtime. But there&rsquo;s no requirement that tools that process our JS code be written in JS themselves, and given that these tools are often computationally demanding, there have been <a href="https://www.notionjs.com/">attempts</a> to create more performant versions in languages like Rust.</p>

<p>The project described here takes that a step further, moving a process normally handled by front end JS libraries to high-performance code via WebAssembly.</p>

<p>The virtual DOM is at the core of how React, Ember, Angular, and Vue &ndash; name any recent front end view framework &ndash; do updates: a virtual representation of the DOM, mirroring the component tree, that can be diffed on updates to avoid making unnecessary updates to the actual DOM.</p>

<p>Dodrio implements the virtual DOM in Rust and does high-throughput transfers to JS to make the actual DOM updates. This raises the question, perhaps, if those updates could in the future be done directly in Wasm via the browser API, but the result is still faster than many of the libraries they benchmarked against.</p>

<h2 id="the-dodrio-api">The Dodrio API</h2>

<p>The API gives ways to manipulate virtual DOM nodes (including state, like counters) and render them. It also includes a Wasm interface for using Javacsript components in Rust:</p>

<pre><code>#[wasm_bindgen]
extern &quot;C&quot; {
    // Import the JS `Greeting` class.
    #[wasm_bindgen(extends = Object)]
    type Greeting;

    // And the `Greeting` class's constructor.
    #[wasm_bindgen(constructor)]
    fn new(who: &amp;str) -&gt; Greeting;
}

// Construct a JS rendering component from a `Greeting` instance.
let js = JsRender::new(Greeting::new(&quot;World&quot;));

</code></pre>

<h2 id="bump-allocation">Bump allocation</h2>

<p>Bump allocators treat allocation like adding to a stack: add new objects to the end, and you can&rsquo;t deallocate existing objects (except all of them at once).</p>

<p>Dodrio bump allocates its virtual DOM trees and the DOM mutations required after each render, batching the changes that will be made to the physical DOM.</p>

<p>Diagram provided by the blog post. Two trees - the two most recent renders - must be kept in memory at a given time:</p>

<pre><code>        ------------------- Time -------------------&gt;
Tree 0: [ render | ------ | diff ]
Tree 1:          [ render | diff | ------ | diff ]
Tree 2:                          [ render | diff | ------ | diff ]
Tree 3:                                          [ render | diff | ------ | diff ]
...

</code></pre>

<p>This is a simple garbage collector that avoid any of the overhead of a general tracing/generational GC.</p>

<h2 id="diffing-and-updating-the-dom">Diffing and updating the DOM</h2>

<p>The diffing process is done by walking the two trees in unison and noting whenever children, attributes, or listeners vary between the two. These changes are translated to instructions in a stack machine, which is read and interpreted in Javascript.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://code.fb.com/core-data/apache-spark-scale-a-60-tb-production-use-case/">Spark at scale at Facebook</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 16 February 2019 ">
                <a title="Permalink" href="https://lukeolney.me/readings/spark-facebook/">16 February 2019</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/spark">Spark</a>
        <a href="/tags/distributed-systems">Distributed Systems</a>
        <a href="/tags/case-studies">Case Studies</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>This blog post details Facebook&rsquo;s migration from Hive to Spark for a particular distributed data processing workload.</p>

<p>Spark is a distributed compute engine, allowing you to write SQL or imperative code that runs in a distributed environment with relatively few accommodations.</p>

<p>Example pipeline (Hive):</p>

<pre><code>Filter -&gt;
Group -&gt;
Reduce
</code></pre>

<p>In this writeup, the core task was to aggregate feature values for each entity_id, target_id pair and shard by entity id:</p>

<pre><code>entity_id, target_id, feature_id, feature_value

-&gt;

// Aggregation could be something like this - not explicit in writeup
entity_id, target_id: &lt;average, sum, ..&gt; feature_value for feature_id
</code></pre>

<p>In Hive, each step outputs a temporary table (stored in the HDFS) that serves as the input to the next step. Because this involved serializing and writing files to HDFS repeatedly along the way, this had a pretty severe performance cost in time and CPU hours.</p>

<p>In the Spark implementation described here, each step is instead combined into a single MapReduce job.</p>

<p>They also note some contributions to Spark to improve its reliability, where the great size of their workload revealed some cracks - especially where hardcoded limits proved to be too restrictive.</p>

<p>E.g., <a href="https://github.com/apache/spark/pull/12285/files">this pull request</a> solves a problem when a reducer&rsquo;s memory is fully allocated. Memory is taken up both by the pointer array (which is the array that&rsquo;s sorted) and the records pointed to by it. Initially, the code would reset the pointer array first (allocating new memory) then free the records, which could cause OoM errors unnecessarily.</p>

            </div>
        </div>
    </section>
</article>  
            <h2 class="list-title">2018</h2>
             <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://daniel.haxx.se/http3-explained/">HTTP/3 Explained</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 30 December 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/http3/">30 December 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/networking">Networking</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                

<p>HTTP/3 is the evolution of the HTTP standard with UDP. It’s based on a new transport-layer protocol called QUIC, which allows better parallelism of the features of HTTP/2.</p>

<p>HTTP/2 introduced multiplexing, which lets the browser send multiple requests without first waiting for the response. This appears parallel at the HTTP level, but it still relies on a single TCP connection. That means that any lost packet will hold up the chain of requests until that packet can be re-transmitted.</p>

<p>HTTP/3&rsquo;s solution continues to use a single connection, but allows transmission from other logical streams while waiting for a lost packet to be retransmitted. That requires implementing a new protocol that retains TCP’s features but allows more control over transmission of packets.</p>

<h2 id="streams">Streams</h2>

<p>QUIC brings HTTP streams to the transport layer. They are independently flow-controlled and independently head-blocked, with prioritization still done at the HTTP layer.</p>

<h2 id="ossification">Ossification</h2>

<p>Changing standards like TCP comes with costs: The Internet relies on a lot of intermediaries to survive, but many are not frequently updated — they will often drop packets on seeing TCP options that they don’t recognize. QUIC gets around this by operating purely with secure connections, preventing intermediaries from inspecting traffic.</p>

<p>This has been a problem with TCP Fast Open, the standard that allows sending data on the first handshake transmission. QUIC offers its own fast open handshake to address that.</p>

<p>Regardless, there are still barriers to using UDP as a transport - many routers block UDP traffic on the standard HTTP ports, for example. This means that HTTP/1 or /2 will still have to exist as a fallback and that connections to unknown hosts will have to be initiated that way.</p>

<h2 id="adoption">Adoption</h2>

<p>It’s already in use across much of the Internet - 7% of all Internet traffic in 2017. While the original Google-introduced protocol was just for HTTP, the IETF version includes a layer for non-HTTP protocols. The implementation for that is still in progress.</p>

<p>Adoption requires coordinating support among those who determine the path of the web, including browser vendors, Apache and nGinx, and TSL implementors.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://docs.aws.amazon.com/aws-technical-content/latest/microservices-on-aws/microservices-on-aws.pdf?icmpid=link_from_whitepapers_page">Service Discovery</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 02 December 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/service-discovery/">02 December 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/aws">AWS</a>
        <a href="/tags/microservices">microservices</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                

<p>Service discovery deals with the problem of mapping services to IPs: If a load balancer wants to send a request to an API server, how does it figure out which ip address to sent it to? This AWS whitepaper gives a high level overview and trade-offs to a couple of approaches:</p>

<h2 id="domains-names-and-load-balancers">Domains Names and Load Balancers</h2>

<p>Alias service domain names (using CNAME records) to the load balancer, which routes to the correct service based on path or host name. This is vulnerable to DNS caching, but you can mitigate that with a short TTL.</p>

<h2 id="dns">DNS</h2>

<p>You can also use DNS to route requests directly to the service. Route 53 allows you to restrict access to services in your own virtual private cloud.</p>

<h2 id="configuration-management">Configuration management</h2>

<p>Map service names to IP addresses in your configuration, which you can set on server start. In particular, you can have new service register with a central configuration manager like AWS OpsWorks.</p>

<p>This is also the basis for frameworks like <a href="https://github.com/Netflix/eureka">Netflix Eurkea</a> or <a href="https://stripe.com/blog/service-discovery-at-stripe">Consul</a>.</p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://openid.net/specs/openid-connect-basic-1_0.html">OpenID Connect 1.0 Spec</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 22 October 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/openid-connect-1.0/">22 October 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/web">Web</a>
        <a href="/tags/authentication">Authentication</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>OpenID connect is based on OAuth 2.0, building on the simple access tokens of the latter to standardize a more complete login system. While OAuth is only specified as an authorization process, leaving authentication, if they chose to include that, up to implementors, OpenID specifies ways for the OAuth server to to answer claims about the end user. That gives it a standard way to perform both authentication and authorization.</p>

<p>It makes use in several cases of JSON Web Tokens, the format for making cryptographically-verifiable claims.</p>

<p>The main addition is that of the ID Token, which contains a &lsquo;subject identitifier&rsquo; field as well as claims about, for instance, the identity of the issuer. This is suplemented by the UserInfo request, which allows the client to ask questions about the user. Standard claims include personally-identifiable information like name and birthdate.</p>

<p>The specification provided this diagram, and I&rsquo;ve filled in the terms:</p>

<pre><code>+--------+                                   +--------+
|        |                                   |        |
|        |---(1) Authentication Request-----&gt;|        |
|        |                                   |        |
|        |  +--------+                       |        |
|        |  |        |                       |        |
|        |  |  End-  |&lt;--(2) AuthN &amp; AuthZ--&gt;|        |
|        |  |  User  |                       |        |
|  OAuth |  |        |                       | OAuth  |
| Client |  +--------+                       | Server |
|        |                                   |        |
|        |&lt;---(3) Authentication Response----|        |
|        |                                   |        |
|        |---------(4) UserInfo Request-----&gt;|        |
|        |                                   |        |
|        |&lt;--------(5) UserInfo Response-----|        |
|        |                                   |        |
+--------+                                   +--------+
</code></pre>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://krebsonsecurity.com/2017/01/who-is-anna-senpai-the-mirai-worm-author/">Who is Anna-Senpai, the Mirai Worm Author</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 18 October 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/mirai/">18 October 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/security">Security</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>This is Brian Krebs&rsquo; fascinating investigative report into the Mirai botnet, the network used to launch some of the largest DDoS attacks on the Internet to date. Krebs&rsquo; account include testimony and private conversations with the hackers themselves, who were later charged by the FBI for their activities. It reveals how much the Internet remains a free-for-all, kill-or-be-killed world, where rogue security companies can surreptitiously hijack competitors&rsquo; IP addresses<a href="https://en.wikipedia.org/wiki/BGP_hijacking">1</a> or take down their services with DDoS hits.</p>

<p>Mirai was the covert arm of a legitimate business, ProTraf Solutions, which offered DDoS protection services in the competitive Minecraft server cottage industry. In early attacks, it sought competitive advantage by DDoSing a competing service, ProxyPipe, which forced many of ProxyPipe&rsquo;s customers to switch to ProTraf.</p>

<p>Krebs is able to connect ProTraf CEO&rsquo;s description of his programming language skills to that of his blackhat persona &ndash; and professed Mirai author &ndash; Anna-Senpai. He also mentions a Github username, shared among a number of online accounts that includes a number of Minecraft forums and a Reddit account. This has several interesting posts, including awfully suspicious speculation about the nature of a DDoS attack on the Rutgers campus.</p>

<p>After the ProxyPipe CEO, remarkably, managed through several layers of ISPs to get the Ukrainian-based control servers for the botnet disconnected, Anna-Senpai taunts him with the knowledge he is responsible. This is just one piece of evidence for his petty-vindictive persona &ndash; he is constantly taking down people he gets into disagreements with, like a hapless server operator and, on multiple occasions, Krebs himself.</p>

<p>The ProxyPipe CEO evenutally makes the connection that Krebs describes between Anna-Senpai and his real life persona. In fact, the two had previously been friends and collaborators on Minecraft projects, before, he says, Anna-Senpai fell to the bad influence of places like Hackforums.net.</p>

<p>His sloppiness with his online personas and his hubris eventually does the Mirai creator in, as the FBI track him down after a broad investigation. He is indicted, and now, as of the time of writing, serves the FBI as part of a plea agreement.<a href="http://www2.philly.com/philly/business/mirai-cyberattack-rutgers-student-paras-jha-fbi-20180919.html">2</a></p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://googleprojectzero.blogspot.com/2018/09/a-cache-invalidation-bug-in-linux.html">Linux Cache Invalidation Bug</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 02 October 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/linux-cache-invalidation-bug/">02 October 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/systems">Systems</a>
        <a href="/tags/security">Security</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>This is a detailed writeup from Project Zero about a bug in the Linux Kernel, introduced through an optimization with an unconsidered edge case.</p>

<p>A quick summary of the relevant OS concepts: Virtual Memory Areas (VMAs), which include the code segment, data segment, and heap, have special rules[1] that must be applied when a page fault occurs. The mappings of addresses to VMAs are stored in <code>vm_area_struct</code>s, which are stored in a red-black tree or possibly cached in a per-thread 4-member array. Whenever a VMA is freed in any thread for the process, all of these per-thread caches must be invalidated.</p>

<p>To avoid having to do this expensive operation, each cache is tagged with a <code>seqnum</code> equal to the <code>seqnum</code> of the per-process <code>mm_struct</code>; when the <code>seqnum</code>s are out of sync, we know to invalidate the cache. Because the <code>seqnum</code> can overflow, though, we still need to flush all the caches every time that happens.</p>

<p>In the patch in question, someone added the further optimization of simply avoiding the flush if the process is single-threaded. They reasoned that VMA lookups would always trigger the update of the cache <code>seqnum</code> and <code>mm_struct</code> <code>seqnum</code> simultaneously, avoiding the need for the flush.</p>

<p>However, this added a (normally) rather unlikely bug in the case that, immediately after incrementing the <code>mm_struct</code> <code>seqnum</code> to wrap to zero, a second thread is created, pushing the <code>seqnum</code> back up to <code>0xffffffff</code> and making the cache in the first thread appear valid again.</p>

<p>The authors manage to exploit the bug first by doing a large number of VMA remappings to trigger the overflow, then creating a fake VMA using the pointers from the deallocated one &ndash; leaked to logs by a warning message &ndash; to bypass Kernel controls. The VMA contains a fault handler that is used on page faults, which can be used, for instance, to run a binary with root privileges.</p>

<p>[1] <a href="http://students.mimuw.edu.pl/SO/Linux/Kod/include/linux/mm.h.html">http://students.mimuw.edu.pl/SO/Linux/Kod/include/linux/mm.h.html</a></p>

            </div>
        </div>
    </section>
</article>  <article class="preview">
    <header>
        <h1 class="post-title">
            <a href="https://pdfs.semanticscholar.org/6a39/082e14e08fcc4f853b07e4d797163afadde1.pdf">Log Structured Merge Trees</a>
        </h1>
        <div class="post-meta">
            <time datetime=" 19 May 2018 ">
                <a title="Permalink" href="https://lukeolney.me/readings/log-structured-merge-trees/">19 May 2018</a>
            </time>
            <ul class="article-taxonomy">
     
    <li>
        <i class="fa fa-tags"></i>
        <a href="/tags/databases">Databases</a>
        <a href="/tags/data-structures">Data Structures</a>
    </li>
    
</ul>
        </div>
    </header>
    <section class="post-excerpt">
        <div class="center">
            <i class="fa fa-spinner fa-spin"></i>
        </div>
        <div class="article-content">
            <div class="readmore" hidden=true>
                <p>The log-structured merge tree is used in the storage engine of many databases, including Cassandra<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>. It describes a data structure, often contrasted with B-trees, that&rsquo;s mainly designed as a strategy for managing writes to disk.</p>

<p>The basic approach is this: Maintain a collection of stores, increasing geometrically in size from the top down. Store records in the top level first. When level L_i fills up, merge it into L_i+1, emptying L_i.</p>

<p>Each level is itself a key-value store. Lower levels are implemented as B+ trees, filled in breadth-first order to avoid wasting space and allow for more sequential reads. Lookups proceed by checking for the key in L_0, then proceeding to the next level if the key isn&rsquo;t found.</p>

<pre><code>        [][][]               &lt;--- L_0: memory (updated in place)
      [][][][][][]           &lt;--- L_1: disk (updated with a merge)
[][][][][][][][][][][][]     &lt;--- L_2: disk (updated with a merge)
</code></pre>

<p>The log-structured approach contrasts with the update-in-place approach: while the former does sequential writes, relying on additional sequential IO to manage the structure asynchronously, the latter does random reads &ndash; relying on a single seek for each read.</p>

<p>The bLSM<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup> authors note the choice that web services face when storing small objects: optimize for low-latency reads, or for high-throughput writes. B-trees meet the former requirement, and LSMTs meet the latter by making sure that all writes to disk are batched.</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_manage_ondisk_c.html">https://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_manage_ondisk_c.html</a>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2"><a href="http://www.eecs.harvard.edu/~margo/cs165/papers/gp-lsm.pdf">http://www.eecs.harvard.edu/~margo/cs165/papers/gp-lsm.pdf</a>
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
</ol>
</div>

            </div>
        </div>
    </section>
</article>  
        </div>

        


<ul class="page-links">
  <li 
    class="page-links-disabled">
    <a href="" aria-label="Previous"><span aria-hidden="true">&lt;&#160;</span></a>
  </li>
  
  
  
  
  
   
    
    
  
  
    <li
      class="page-links-active"><a href="/readings/">1</a>
    </li>
    
  
  
  
  
   
    
    
  
  
    <li
      ><a href="/readings/page/2/">2</a>
    </li>
    
  
  
  
  
   
    
    
  
  
    <li
      ><a href="/readings/page/3/">3</a>
    </li>
    
  
  <li
    >
    <a href="/readings/page/2/" aria-label="Next"><span aria-hidden="true">&#160;&gt;</span></a>
  </li>
</ul>



</main>

<footer class="footer">
  <ul class="footer-links">
    <li>
      <a href="https://github.com/lolney">
        <i class="fa fa-github"></i> Github</a>
    </li>
  </ul>
</footer>

</div>

</body>

</html>